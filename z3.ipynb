{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# z3: Data Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Data Engineering Capstone Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### First run the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Downloading https://files.pythonhosted.org/packages/30/5f/2e5c564bd86349fe6b82ca840f46acf6f4bb76d79ba9057fce3d3e008864/python_dotenv-0.20.0-py3-none-any.whl\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-0.20.0\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "from base.z3_base import z3Base\n",
    "from z3_nodes.z3_inventory import z3Inventory\n",
    "from z3_nodes.z3_sellout import z3Sellout\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_columns = 50\n",
    "pd.set_option(\"display.float_format\", lambda x: \"%.5f\" % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Then run the cell below\n",
    "Now the z3 will show here the data, first of all I used the client_id for privacy purposes, also de provider_id, but imagine you query the actual name of each client and provider, so now we know the suspicious dailys that may have useless values.\n",
    "\n",
    "In the next cell we can see that posibly the provider 18 for the client 1 has only 1 row in its report, that looks very suspicious, the next step would be to download the raw file and check if the information was downloaded in that way if so, the problem was the site so next we restart the scrapper execution and delete the records loaded.\n",
    "Same for client 1 and provider 19.\n",
    "There's also a case of higher than expected values we can see that with the client 3 and provider 29, on both indicators scrapper_pos_sales and scrapper_rows, those are very high than expected for that site, giving you some context that website returns 1000 rows at maximum, that day has 7319!!."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>provider_id</th>\n",
       "      <th>daily</th>\n",
       "      <th>scrapper_pos_qty</th>\n",
       "      <th>scrapper_pos_sales</th>\n",
       "      <th>scrapper_curr_on_hand_qty</th>\n",
       "      <th>scrapper_rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2022/05/01</td>\n",
       "      <td>972.00000</td>\n",
       "      <td>104458.49900</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>98.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>2022/04/21</td>\n",
       "      <td>35960.00000</td>\n",
       "      <td>332503.70000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>543.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>2022/04/23</td>\n",
       "      <td>12409.00000</td>\n",
       "      <td>122844.38000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>617.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>2022/04/26</td>\n",
       "      <td>17017.00000</td>\n",
       "      <td>162978.96000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>561.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>2022/04/28</td>\n",
       "      <td>17401.00000</td>\n",
       "      <td>193816.96000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>533.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>2022/05/01</td>\n",
       "      <td>951.00000</td>\n",
       "      <td>14379.88000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>207.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>2022/05/02</td>\n",
       "      <td>764.00000</td>\n",
       "      <td>10936.39000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>156.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2022/04/18</td>\n",
       "      <td>0.12500</td>\n",
       "      <td>58.50000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2022/04/30</td>\n",
       "      <td>4897.97930</td>\n",
       "      <td>45712.67000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>24.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>2022/05/01</td>\n",
       "      <td>0.68750</td>\n",
       "      <td>478.84000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>2022/05/02</td>\n",
       "      <td>0.68750</td>\n",
       "      <td>478.84000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>2022/05/02</td>\n",
       "      <td>18890.20000</td>\n",
       "      <td>59886.36000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>44.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>2022/04/20</td>\n",
       "      <td>10870.00000</td>\n",
       "      <td>231016.46005</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4688.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>2022/04/27</td>\n",
       "      <td>17736.00000</td>\n",
       "      <td>363973.23993</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>7319.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2022/04/30</td>\n",
       "      <td>974.00000</td>\n",
       "      <td>42486.65000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>353.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    client_id  provider_id       daily  scrapper_pos_qty  scrapper_pos_sales  \\\n",
       "0           1            6  2022/05/01         972.00000        104458.49900   \n",
       "1           1           14  2022/04/21       35960.00000        332503.70000   \n",
       "2           1           14  2022/04/23       12409.00000        122844.38000   \n",
       "3           1           14  2022/04/26       17017.00000        162978.96000   \n",
       "4           1           14  2022/04/28       17401.00000        193816.96000   \n",
       "5           1           14  2022/05/01         951.00000         14379.88000   \n",
       "6           1           14  2022/05/02         764.00000         10936.39000   \n",
       "7           1           18  2022/04/18           0.12500            58.50000   \n",
       "8           1           18  2022/04/30        4897.97930         45712.67000   \n",
       "9           1           19  2022/05/01           0.68750           478.84000   \n",
       "10          1           19  2022/05/02           0.68750           478.84000   \n",
       "11          1           21  2022/05/02       18890.20000         59886.36000   \n",
       "12          3           29  2022/04/20       10870.00000        231016.46005   \n",
       "13          3           29  2022/04/27       17736.00000        363973.23993   \n",
       "14          6            1  2022/04/30         974.00000         42486.65000   \n",
       "\n",
       "    scrapper_curr_on_hand_qty  scrapper_rows  \n",
       "0                     0.00000       98.00000  \n",
       "1                     0.00000      543.00000  \n",
       "2                     0.00000      617.00000  \n",
       "3                     0.00000      561.00000  \n",
       "4                     0.00000      533.00000  \n",
       "5                     0.00000      207.00000  \n",
       "6                     0.00000      156.00000  \n",
       "7                     0.00000        1.00000  \n",
       "8                     0.00000       24.00000  \n",
       "9                     0.00000        2.00000  \n",
       "10                    0.00000        2.00000  \n",
       "11                    0.00000       44.00000  \n",
       "12                    0.00000     4688.00000  \n",
       "13                    0.00000     7319.00000  \n",
       "14                    0.00000      353.00000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<z3_nodes.z3_sellout.z3Sellout at 0x7f4e58185fd0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z3Sellout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Then run the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>provider_id</th>\n",
       "      <th>daily</th>\n",
       "      <th>scrapper_pos_qty</th>\n",
       "      <th>scrapper_pos_sales</th>\n",
       "      <th>scrapper_curr_on_hand_qty</th>\n",
       "      <th>scrapper_rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2022/04/21</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>11730.00000</td>\n",
       "      <td>80.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2022/04/28</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>7410.00000</td>\n",
       "      <td>63.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2022/04/27</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1029466.00000</td>\n",
       "      <td>3001.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2022/04/27</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>291430.00000</td>\n",
       "      <td>301.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2022/05/01</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>156.14583</td>\n",
       "      <td>3.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2022/05/02</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>156.14583</td>\n",
       "      <td>3.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>2022/05/01</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>927.39583</td>\n",
       "      <td>17.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>2022/05/02</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>927.39583</td>\n",
       "      <td>17.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2022/04/27</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>132980.00000</td>\n",
       "      <td>2171.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>2022/04/20</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>527538.00000</td>\n",
       "      <td>552.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>2022/04/21</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1317.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>2022/04/23</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1450.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>2022/04/24</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1668.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>2022/04/26</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1439.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>2022/04/27</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>16690.00000</td>\n",
       "      <td>1091.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>2022/04/29</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>7980.00000</td>\n",
       "      <td>1324.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>2022/04/30</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>6250.00000</td>\n",
       "      <td>1454.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>2022/05/03</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1478.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>2022/05/04</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1357.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>2022/05/05</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1258.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>2022/05/06</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1251.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>2022/05/07</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1369.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>2022/04/27</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>229382.00000</td>\n",
       "      <td>1985.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>2022/04/18</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1324.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>2022/04/19</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1038.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>2022/04/20</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4680.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>2022/04/21</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1204.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>2022/04/22</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>793.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>2022/04/23</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>975.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>2022/04/24</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1475.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>2022/04/25</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1263.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>2022/04/26</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1356.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>2022/04/27</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>7319.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>2022/04/28</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1195.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>2022/04/29</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1958.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>2022/05/01</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1817.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>2022/05/02</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1360.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>2022/05/03</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>980.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>2022/05/04</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1703.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>2022/05/05</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>845.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>2022/05/06</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>773.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>2022/05/07</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>996.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>2022/04/24</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>270.00000</td>\n",
       "      <td>3928.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>2022/05/01</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4140.00000</td>\n",
       "      <td>3955.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2022/04/21</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2944.00000</td>\n",
       "      <td>193.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2022/04/28</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2089.00000</td>\n",
       "      <td>142.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2022/05/04</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>71794.00000</td>\n",
       "      <td>2598.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2022/05/05</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>71781.00000</td>\n",
       "      <td>2620.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2022/05/06</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>71408.00000</td>\n",
       "      <td>2620.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2022/05/07</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>70736.00000</td>\n",
       "      <td>2616.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>2022/04/27</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>257712.00000</td>\n",
       "      <td>5256.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    client_id  provider_id       daily  scrapper_pos_qty  scrapper_pos_sales  \\\n",
       "0           1            1  2022/04/21           0.00000             0.00000   \n",
       "1           1            1  2022/04/28           0.00000             0.00000   \n",
       "2           1           11  2022/04/27           0.00000             0.00000   \n",
       "3           1           12  2022/04/27           0.00000             0.00000   \n",
       "4           1           18  2022/05/01           0.00000             0.00000   \n",
       "5           1           18  2022/05/02           0.00000             0.00000   \n",
       "6           1           19  2022/05/01           0.00000             0.00000   \n",
       "7           1           19  2022/05/02           0.00000             0.00000   \n",
       "8           2           11  2022/04/27           0.00000             0.00000   \n",
       "9           2           15  2022/04/20           0.00000             0.00000   \n",
       "10          2           24  2022/04/21           0.00000             0.00000   \n",
       "11          2           24  2022/04/23           0.00000             0.00000   \n",
       "12          2           24  2022/04/24           0.00000             0.00000   \n",
       "13          2           24  2022/04/26           0.00000             0.00000   \n",
       "14          2           24  2022/04/27           0.00000             0.00000   \n",
       "15          2           24  2022/04/29           0.00000             0.00000   \n",
       "16          2           24  2022/04/30           0.00000             0.00000   \n",
       "17          2           24  2022/05/03           0.00000             0.00000   \n",
       "18          2           24  2022/05/04           0.00000             0.00000   \n",
       "19          2           24  2022/05/05           0.00000             0.00000   \n",
       "20          2           24  2022/05/06           0.00000             0.00000   \n",
       "21          2           24  2022/05/07           0.00000             0.00000   \n",
       "22          3           11  2022/04/27           0.00000             0.00000   \n",
       "23          3           29  2022/04/18           0.00000             0.00000   \n",
       "24          3           29  2022/04/19           0.00000             0.00000   \n",
       "25          3           29  2022/04/20           0.00000             0.00000   \n",
       "26          3           29  2022/04/21           0.00000             0.00000   \n",
       "27          3           29  2022/04/22           0.00000             0.00000   \n",
       "28          3           29  2022/04/23           0.00000             0.00000   \n",
       "29          3           29  2022/04/24           0.00000             0.00000   \n",
       "30          3           29  2022/04/25           0.00000             0.00000   \n",
       "31          3           29  2022/04/26           0.00000             0.00000   \n",
       "32          3           29  2022/04/27           0.00000             0.00000   \n",
       "33          3           29  2022/04/28           0.00000             0.00000   \n",
       "34          3           29  2022/04/29           0.00000             0.00000   \n",
       "35          3           29  2022/05/01           0.00000             0.00000   \n",
       "36          3           29  2022/05/02           0.00000             0.00000   \n",
       "37          3           29  2022/05/03           0.00000             0.00000   \n",
       "38          3           29  2022/05/04           0.00000             0.00000   \n",
       "39          3           29  2022/05/05           0.00000             0.00000   \n",
       "40          3           29  2022/05/06           0.00000             0.00000   \n",
       "41          3           29  2022/05/07           0.00000             0.00000   \n",
       "42          4           24  2022/04/24           0.00000             0.00000   \n",
       "43          4           24  2022/05/01           0.00000             0.00000   \n",
       "44          6            1  2022/04/21           0.00000             0.00000   \n",
       "45          6            1  2022/04/28           0.00000             0.00000   \n",
       "46          6            3  2022/05/04           0.00000             0.00000   \n",
       "47          6            3  2022/05/05           0.00000             0.00000   \n",
       "48          6            3  2022/05/06           0.00000             0.00000   \n",
       "49          6            3  2022/05/07           0.00000             0.00000   \n",
       "50          6           11  2022/04/27           0.00000             0.00000   \n",
       "\n",
       "    scrapper_curr_on_hand_qty  scrapper_rows  \n",
       "0                 11730.00000       80.00000  \n",
       "1                  7410.00000       63.00000  \n",
       "2               1029466.00000     3001.00000  \n",
       "3                291430.00000      301.00000  \n",
       "4                   156.14583        3.00000  \n",
       "5                   156.14583        3.00000  \n",
       "6                   927.39583       17.00000  \n",
       "7                   927.39583       17.00000  \n",
       "8                132980.00000     2171.00000  \n",
       "9                527538.00000      552.00000  \n",
       "10                    0.00000     1317.00000  \n",
       "11                    0.00000     1450.00000  \n",
       "12                    0.00000     1668.00000  \n",
       "13                    0.00000     1439.00000  \n",
       "14                16690.00000     1091.00000  \n",
       "15                 7980.00000     1324.00000  \n",
       "16                 6250.00000     1454.00000  \n",
       "17                    0.00000     1478.00000  \n",
       "18                    0.00000     1357.00000  \n",
       "19                    0.00000     1258.00000  \n",
       "20                    0.00000     1251.00000  \n",
       "21                    0.00000     1369.00000  \n",
       "22               229382.00000     1985.00000  \n",
       "23                    0.00000     1324.00000  \n",
       "24                    0.00000     1038.00000  \n",
       "25                    0.00000     4680.00000  \n",
       "26                    0.00000     1204.00000  \n",
       "27                    0.00000      793.00000  \n",
       "28                    0.00000      975.00000  \n",
       "29                    0.00000     1475.00000  \n",
       "30                    0.00000     1263.00000  \n",
       "31                    0.00000     1356.00000  \n",
       "32                    0.00000     7319.00000  \n",
       "33                    0.00000     1195.00000  \n",
       "34                    0.00000     1958.00000  \n",
       "35                    0.00000     1817.00000  \n",
       "36                    0.00000     1360.00000  \n",
       "37                    0.00000      980.00000  \n",
       "38                    0.00000     1703.00000  \n",
       "39                    0.00000      845.00000  \n",
       "40                    0.00000      773.00000  \n",
       "41                    0.00000      996.00000  \n",
       "42                  270.00000     3928.00000  \n",
       "43                 4140.00000     3955.00000  \n",
       "44                 2944.00000      193.00000  \n",
       "45                 2089.00000      142.00000  \n",
       "46                71794.00000     2598.00000  \n",
       "47                71781.00000     2620.00000  \n",
       "48                71408.00000     2620.00000  \n",
       "49                70736.00000     2616.00000  \n",
       "50               257712.00000     5256.00000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<z3_nodes.z3_inventory.z3Inventory at 0x7f4df8a4e1c0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z3Inventory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Run the cell below only if you want to delete the tables in z3_results database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "z3Base.drop_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## I have done all my project on python files, from here I will use code snippets to explain each step on the process, the cells are not intended to run exactly as is intended in the \"run the program\" part above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 1: Scope the project and gather the data\n",
    "I will use the data from our clients databases,  I will anonymize an example of the raw data extracted from the databases, the data sources which are each database are more than 2 as it's expected in the project rubric. As it's defined in the anonymized datasets, the raw data extracted from the database surpasses 5 million rows on each report type (sellout, inventory). From those rows it summarizes the indicators pos qty, pos sales (sellout) and curr on hand qty (inventory) and groups it into the report daily (the date to which the data corresponds).\n",
    "\n",
    "\n",
    "**Correction**\n",
    "The base tables sellout and inventory interact with 4 different tables, the first one is the historical_execution_results that let us improve the query performance, that one is used in the query. Helps me to know what execution ids I must filter by id instead of filtering the sellout by a date range in this case the comparation would be against millions of rows.\n",
    "\n",
    "The second one is the config reports table that is loaded as a variable for each client, this variable is a copy from the config report table of scrapper database, with only 2 important values first the provider as the key and second the config report id, the config report id let us know what specific report are we talking about, that specific report_id is combined into the extract query, and having that file in local instead of performing another query allows us to save some connections, let's say our database instances usually carry 20 out of 10 connections, what I mean is that they are always overwhelmed. Here's an example:\n",
    "\n",
    "CLIENT_1=\"{\n",
    "    'SELLOUT':{\n",
    "        'PROVIDER': 18,\n",
    "        'PROVIDER: 17,\n",
    "        'PROVIDER': 13,\n",
    "        'PROVIDERY': 14\n",
    "    }\"\n",
    "\n",
    "\n",
    "The other two important tables are hidden into the .env file, there I show the client name and client_id, provider name and provider_id, to correlate the provider name, and client name into the actual report that is being queried, the value of the dictionary assigns an id for each provider/client. So I know to which client and provider each report belongs to.\n",
    "\n",
    "That combination happens in the extract function:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from pandas import DataFrame\n",
    "\n",
    "def _extract(self) -> Tuple[DataFrame, bool]:\n",
    "    \"\"\"Performs the extraction query and inserts the client, and provider\n",
    "    of each request.\n",
    "\n",
    "    @return df: the dataframe that is the result of the query.\n",
    "    @return empty_df: a boolean that tells you if the dataframe is empty or not.\n",
    "    \"\"\"\n",
    "    df: DataFrame = self._perform_extract_query()\n",
    "    self.z3_raw_data = pd.concat([df, self.z3_raw_data])\n",
    "    df['scrapper_rows'] = 1\n",
    "    if self.report_type == 'INVENTORY':\n",
    "        change_column_datatype(df, 'scrapper_curr_on_hand_qty', 'float')\n",
    "    else:\n",
    "        change_column_datatype(df, 'scrapper_pos_sales', 'float')\n",
    "        change_column_datatype(df, 'scrapper_pos_qty', 'float')\n",
    "\n",
    "    df: DataFrame = df.groupby('daily').aggregate('sum')\n",
    "    df: DataFrame = pd.DataFrame(df.reset_index())\n",
    "    df['client'] = self.client # <--------------------------- Here\n",
    "    df['provider'] = self.provider # <----------------------- Here\n",
    "    empty_df: int = df.shape[0]\n",
    "    empty_df: bool = empty_df == 0\n",
    "    return df, empty_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "\n",
    "Example of the tables/dictionaries:\n",
    " \n",
    "PROVIDER_IDS=\"{\n",
    "    'PROVIDER': 1,\n",
    "    'PROVIDER': 2,\n",
    "    'PROVIDER': 3,\n",
    "    'PROVIDER': 4,\n",
    "    'PROVIDER': 5,\n",
    "\n",
    "\n",
    "CLIENT_IDS=\"{\n",
    "    'CLIENT': 1,\n",
    "    'CLIENT': 2,\n",
    "    'CLIENT': 3,\n",
    "    'CLIENT': 4,\n",
    "    'CLIENT': 5,\n",
    "    'CLIENT': 6,\n",
    "    'CLIENT': 7\n",
    "}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>daily</th>\n",
       "      <th>scrapper_pos_qty</th>\n",
       "      <th>scrapper_pos_sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022/04/11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022/04/11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022/04/11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022/04/11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022/04/11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>97.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022/04/11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>111.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022/04/11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>103.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022/04/11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>95.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022/04/11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>97.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022/04/11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>103.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        daily  scrapper_pos_qty  scrapper_pos_sales\n",
       "0  2022/04/11               1.0               45.74\n",
       "1  2022/04/11               1.0               46.55\n",
       "2  2022/04/11               1.0               50.00\n",
       "3  2022/04/11               1.0               91.20\n",
       "4  2022/04/11               1.0               97.41\n",
       "5  2022/04/11               1.0              111.02\n",
       "6  2022/04/11               1.0              103.36\n",
       "7  2022/04/11               1.0               95.37\n",
       "8  2022/04/11               1.0               97.41\n",
       "9  2022/04/11               1.0              103.36"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_columns = 50\n",
    "pd.set_option(\"display.float_format\", lambda x: \"%.5f\" % x)\n",
    "\n",
    "df = pd.read_csv('raw_data_SELLOUT.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 2: Explore and asses the data\n",
    "As I said in the project scope the two most important problems for us are when indicators have an extremely high value (duplicated) or extremely low values, I will solve this by taking the outlier limits that are calculated by substracting inter quartile range * 1.5 to quartile 1 or adding it to quartile 3, but instead I will use inter quartil range * 3, because I dont need to find data variability outliers instead only extreme ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_columns = 50\n",
    "pd.set_option(\"display.float_format\", lambda x: \"%.5f\" % x)\n",
    "\n",
    "df = pd.read_csv('raw_data_SELLOUT.csv')\n",
    "df = df.groupby('daily').aggregate('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scrapper_pos_qty</th>\n",
       "      <th>scrapper_pos_sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>31.00000</td>\n",
       "      <td>31.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1455139.27057</td>\n",
       "      <td>34048785.33055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>310791.69812</td>\n",
       "      <td>6636149.44017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>828393.10000</td>\n",
       "      <td>16811180.81787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1312710.50085</td>\n",
       "      <td>32506898.93931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1528647.35510</td>\n",
       "      <td>35323766.01079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1596825.05735</td>\n",
       "      <td>37921888.60274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2058449.09200</td>\n",
       "      <td>46030551.08599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       scrapper_pos_qty  scrapper_pos_sales\n",
       "count          31.00000            31.00000\n",
       "mean      1455139.27057      34048785.33055\n",
       "std        310791.69812       6636149.44017\n",
       "min        828393.10000      16811180.81787\n",
       "25%       1312710.50085      32506898.93931\n",
       "50%       1528647.35510      35323766.01079\n",
       "75%       1596825.05735      37921888.60274\n",
       "max       2058449.09200      46030551.08599"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 3: Define the data model\n",
    "#### Conceptual model\n",
    "My data model will be a star schema, since we need to analyze specifically numeric indicators, that will tell us what's wrong with the data gathered by the robots, it will be easier for joins and centered on the quantitative indicators.\n",
    "\n",
    "\n",
    "### Database tables\n",
    "#### Fact Table\n",
    "\n",
    "* **indicators** - quantitative values that show the performance of a product.\n",
    "    * client_id, report_id, provider_id, execution_id, daily_id, scrapper_pos_qty, scrapper_pos_sales, scrapper_curr_on_hand_qty, scrapper_rows.\n",
    "\n",
    "#### Dimension Tables\n",
    "\n",
    "* **clients** - Our clients.\n",
    "    * client_id, client\n",
    "* **daily** - The date to which the data belongs.\n",
    "    * daily_id, daily, daily_year, daily_month, daily_day.\n",
    "* **reports** - The report type of the data uploaded.\n",
    "    * report_id, report_type.\n",
    "* **providers** - The store type/brand where the products are being sold. \n",
    "    * provider_id, provider.\n",
    "* **executions** - The identifier of the data that is loaded into the z3_results database once you run any of the nodes (sellout or inventory).\n",
    "    * execution_id, execution_date, execution_year, execution_month, execution_day, execution_hour, execution_minute.\n",
    "\n",
    "#### Mapping out data pipelines\n",
    "* 1. Summarize the data in the database of each client, grouping the results by daily, and saving the columns provider, client, pos qty, pos sales and curr on hand qty columns.\n",
    "* 2. Process the past into a dataframe and apply statistical rules described on step 2 to filter the values we want.\n",
    "* 3. Take the result into a master of all clients and providers, and posible days with extreme values, create the id of each of the dimension tables.\n",
    "* 4. Slice the master dataframe into the star schema tables.\n",
    "* 5. Perform the loading queries for each table.\n",
    "* 6. Run the tests to confirm the data loaded has the same values as the data extracted and processed, I do this with 5 tests, each one correlates with the 3 principal indicators, also the scrapper rows that correspond to the original report uploaded into the clients database, and the total dailys in the results of step 2 must be present in the dailys uploaded that correlate with the execution id.\n",
    "* 7. Apply the zzz, and sleep better, you will be aware if the websites are returning useless data, and the clients will be happy for it.\n",
    "* 8. If needed drop the tables by running the drop_tables method on jupyter lab.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 4: Run pipelines to model the data\n",
    "The pipelines are defined in the **base/z3_base.py** file, the most important methods that let us execute the pipelines are **extract_and_transform_each_provider_and_client()** it's too clear what it does haha! **load()** that takes the results into star schema and uploads into the z3_results database, **data_quality_checks()** that performs tests and **drop_tables()** that gets rid of the tables if needed, the brand new function that **display_results()**.\n",
    "\n",
    "The data dictionary is in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### The next cell is the z3_base.py file that is the heart of this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import datetime as dt\n",
    "import logging\n",
    "import os\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import pytest\n",
    "import pytz\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from pandas import DataFrame\n",
    "\n",
    "from base.constants import columns_quality_checks\n",
    "from base.z3_interface import z3Interface\n",
    "from engineering.engineering import (change_column_datatype,\n",
    "                                     create_date_yyyy_mm_dd,\n",
    "                                     create_date_yyyy_mm_dd_hh_mins)\n",
    "from extract_and_quality.extract_and_quality_queries import quality_checks\n",
    "from load.load_queries import (create_table_queries, drop_table_queries,\n",
    "                               insert_table_queries_dict)\n",
    "\n",
    "\n",
    "class z3Base(z3Interface):\n",
    "    \"\"\"Class that defines and directs the execution of the etl process.\"\"\"\n",
    "    DAILY_FORMAT: str = \"%Y/%m/%d\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Defines the variables that will be used on the etl process.\"\"\"\n",
    "        self.z3_tables_dictionary: Dict[str, str] = {}\n",
    "        load_dotenv(find_dotenv())\n",
    "\n",
    "        self.client_ids = ast.literal_eval(os.getenv(\"CLIENT_IDS\"))\n",
    "        self.provider_ids = ast.literal_eval(os.getenv(\"PROVIDER_IDS\"))\n",
    "        self.report_ids = ast.literal_eval(os.getenv(\"REPORT_IDS\"))\n",
    "\n",
    "        self.z3_indicators_master: DataFrame = pd.DataFrame()\n",
    "        self.z3_dates_table: DataFrame = pd.DataFrame()\n",
    "        self.z3_reports_table: DataFrame = pd.DataFrame()\n",
    "        self.z3_clients_table: DataFrame = pd.DataFrame()\n",
    "        self.z3_providers_table: DataFrame = pd.DataFrame()\n",
    "        self.z3_indicators_table: DataFrame = pd.DataFrame()\n",
    "        self.z3_executions_table: DataFrame = pd.DataFrame()\n",
    "\n",
    "        self.z3_raw_data: DataFrame = pd.DataFrame()\n",
    "\n",
    "        self.z3_results_password_db: str = os.getenv(\"RESULTS_PASSWORD\")\n",
    "        self.z3_results_user_db: str = os.getenv(\"RESULTS_USER_DB\")\n",
    "        self.z3_results_host_db: str = os.getenv(\"RESULTS_HOST_DB\")\n",
    "\n",
    "    def extract_and_transform_each_provider_and_client(self):\n",
    "        \"\"\"Performs the extraction that queries each database for each client\n",
    "        then process the result of the query to filter the data and get only\n",
    "        the extreme values that could be an error from the site.\"\"\"\n",
    "        for self.client in self.clients:\n",
    "            provider_and_config_report_id: Dict[str, Dict] = ast.literal_eval(\n",
    "                os.getenv(self.client.upper().strip()))\n",
    "            provider_and_config_report_id: Dict[str, str] = provider_and_config_report_id.get(\n",
    "                self.report_type)\n",
    "            providers: List[str] = list(provider_and_config_report_id.keys())\n",
    "\n",
    "            self.password_db: str = os.getenv(\"PASSWORD\")\n",
    "            self.user_db: str = os.getenv(\"USER_DB\")\n",
    "            self.host_db: str = os.getenv(\"HOST_DB\") if self.client.upper() not in os.getenv(\n",
    "                \"CLIENTS_DB2\") else os.getenv(\n",
    "                \"HOST_DB_2\")\n",
    "\n",
    "            for self.provider in providers:\n",
    "                self.config_report: int = provider_and_config_report_id.get(\n",
    "                    self.provider)\n",
    "                z3_df, empty_df = self._extract()\n",
    "                if not empty_df:\n",
    "                    z3_indicators, z3_indicators_empty = self._transform(\n",
    "                        z3_df=z3_df)\n",
    "                    if not z3_indicators_empty:\n",
    "                        self.z3_indicators_master = pd.concat(\n",
    "                            [z3_indicators, self.z3_indicators_master])\n",
    "\n",
    "        self.z3_raw_data.to_csv(f'raw_data_{self.report_type}.csv', index=False)\n",
    "        tz = pytz.timezone('America/Mexico_City')\n",
    "        today_mx: dt.date = dt.datetime.now(tz=tz).today()\n",
    "        today_str: str = today_mx.strftime('%Y/%m/%d-%H:%M')\n",
    "        self.z3_indicators_master['execution_date'] = today_str\n",
    "\n",
    "    def _get_date_range(self) -> Tuple[str, str]:\n",
    "        \"\"\"Defines tha date range that will be queried amongst the databases.\n",
    "\n",
    "        @return thirty_days_ago: the date that corresponds thirty days ago before yesterday.\n",
    "        @return yesterday: the date that corresponds to the date before today.\n",
    "        \"\"\"\n",
    "        tz = pytz.timezone('America/Mexico_City')\n",
    "        today_mx: dt.date = dt.datetime.now(tz=tz).today()\n",
    "        yesterday: dt.date = (today_mx - dt.timedelta(days=1))\n",
    "        thirty_days_ago: dt.date = (yesterday - dt.timedelta(days=30))\n",
    "        yesterday: str = yesterday.strftime(self.DAILY_FORMAT)\n",
    "        thirty_days_ago: str = thirty_days_ago.strftime(self.DAILY_FORMAT)\n",
    "\n",
    "        return thirty_days_ago, yesterday\n",
    "\n",
    "    def _extract(self) -> Tuple[DataFrame, bool]:\n",
    "        \"\"\"Performs the extraction query and inserts the client, and provider\n",
    "        of each request.\n",
    "\n",
    "        @return df: the dataframe that is the result of the query.\n",
    "        @return empty_df: a boolean that tells you if the dataframe is empty or not.\n",
    "        \"\"\"\n",
    "        df: DataFrame = self._perform_extract_query()\n",
    "        self.z3_raw_data = pd.concat([df, self.z3_raw_data])\n",
    "        df['scrapper_rows'] = 1\n",
    "        if self.report_type == 'INVENTORY':\n",
    "            change_column_datatype(df, 'scrapper_curr_on_hand_qty', 'float')\n",
    "        else:\n",
    "            change_column_datatype(df, 'scrapper_pos_sales', 'float')\n",
    "            change_column_datatype(df, 'scrapper_pos_qty', 'float')\n",
    "\n",
    "        df: DataFrame = df.groupby('daily').aggregate('sum')\n",
    "        df: DataFrame = pd.DataFrame(df.reset_index())\n",
    "        df['client'] = self.client\n",
    "        df['provider'] = self.provider\n",
    "        empty_df: int = df.shape[0]\n",
    "        empty_df: bool = empty_df == 0\n",
    "        return df, empty_df\n",
    "\n",
    "    def _perform_extract_query(self) -> DataFrame:\n",
    "        \"\"\"Connects to the database selected for each client and does the\n",
    "        query, also gets the result into a dataframe format.\n",
    "\n",
    "        @return df: the data frame that is the result of the query.\n",
    "        \"\"\"\n",
    "        thirty_days_ago, yesterday = self._get_date_range()\n",
    "        db_name: str = f\"scrappers_{self.client.lower()}\"\n",
    "        connection: str = f\"host={self.host_db} dbname={db_name} user={self.user_db} password={self.password_db}\"\n",
    "        df: DataFrame = pd.DataFrame()\n",
    "        conn = psycopg2.connect(connection)\n",
    "        try:\n",
    "            conn.set_session(autocommit=True, readonly=True)\n",
    "            cur = conn.cursor()\n",
    "            query_tuple: Tuple = (self.config_report,\n",
    "                                  thirty_days_ago,\n",
    "                                  yesterday,\n",
    "                                  thirty_days_ago,\n",
    "                                  yesterday)\n",
    "\n",
    "            cur.execute(self.query_db, query_tuple)\n",
    "            df: DataFrame = DataFrame(\n",
    "                cur.fetchall(),\n",
    "                columns=self.columns,\n",
    "            )\n",
    "        except psycopg2.Error as e:\n",
    "            logging.info(e)\n",
    "\n",
    "        finally:\n",
    "            conn.close()\n",
    "\n",
    "        return df\n",
    "\n",
    "    def _transform(self, z3_df: DataFrame) -> Tuple[DataFrame, bool]:\n",
    "        \"\"\"Once we have the raw data this method will filter to look for really\n",
    "        extreme values.\n",
    "\n",
    "        @param z3_df: the raw data from the database.\n",
    "        @return z3_unified: since the data frame is filtered by extreme results for 3 different columns\n",
    "            this dataframe corresponds to each result on the columns altogether in one dataframe.\n",
    "        \"\"\"\n",
    "        indicator_2_emptiness: bool = True\n",
    "        z3_indicator_1, indicator_1_emptiness = self._transform_quantitative_indicators(\n",
    "            z3_df,\n",
    "            self.key_performance_indicator_1\n",
    "        )\n",
    "\n",
    "        if self.key_performance_indicator_2:\n",
    "            z3_indicator_2, indicator_2_emptiness = self._transform_quantitative_indicators(\n",
    "                z3_df,\n",
    "                self.key_performance_indicator_2\n",
    "            )\n",
    "\n",
    "        z3_rows, rows_emptiness = self._transform_quantitative_indicators(\n",
    "            z3_df,\n",
    "            'scrapper_rows'\n",
    "        )\n",
    "\n",
    "        z3_unified: DataFrame = pd.DataFrame()\n",
    "        if not indicator_1_emptiness:\n",
    "            z3_unified: DataFrame = pd.concat([z3_indicator_1, z3_unified])\n",
    "\n",
    "        if not indicator_2_emptiness and self.key_performance_indicator_2:\n",
    "            z3_unified: DataFrame = pd.concat([z3_indicator_2, z3_unified])\n",
    "\n",
    "        if not rows_emptiness:\n",
    "            z3_unified: DataFrame = pd.concat([z3_rows, z3_unified])\n",
    "\n",
    "        z3_unified: DataFrame = z3_unified.drop_duplicates(keep='first')\n",
    "\n",
    "        z3_unified_empty: bool = bool(\n",
    "            indicator_2_emptiness and indicator_1_emptiness)\n",
    "\n",
    "        return z3_unified, z3_unified_empty\n",
    "\n",
    "    def _transform_quantitative_indicators(self, df: DataFrame, column: str) -> Tuple[DataFrame, bool]:\n",
    "        \"\"\"\n",
    "        Receives the raw dataframe and filters the column for its extreme values, using iqr * 3 to look\n",
    "        for extreme outliers.\n",
    "        @param df: the raw dataframe.\n",
    "        @param column: the column to be filtered quantitatively\n",
    "        @return df_fails: the result of the filter that are the possible fails from the website scrapped.\n",
    "        @return empty_df: a boolean that shows if there wasnt any extreme results.\n",
    "        \"\"\"\n",
    "        first_q: float = np.percentile(df[column], 25)\n",
    "        third_q: float = np.percentile(df[column], 75)\n",
    "\n",
    "        iqr: float = third_q - first_q\n",
    "        lower_limit: float = first_q - (iqr * 3)\n",
    "        lower_limit: float = lower_limit if lower_limit > 0 else 1\n",
    "        upper_limit: float = third_q + (iqr * 3)\n",
    "\n",
    "        df_lower: DataFrame = df[df[column] < lower_limit]\n",
    "        df_upper: DataFrame = df[df[column] > upper_limit]\n",
    "\n",
    "        df_fails: DataFrame = pd.DataFrame()\n",
    "        df_fails: DataFrame = pd.concat([df_lower, df_fails])\n",
    "        df_fails: DataFrame = pd.concat([df_upper, df_fails])\n",
    "\n",
    "        empty_df: int = df_fails.shape[0]\n",
    "        empty_df: bool = empty_df == 0\n",
    "        df_fails['report_type'] = self.report_type\n",
    "\n",
    "        return df_fails, empty_df\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\"Slices the z3_indicators_master dataframe that agglomerates the data\n",
    "        from all the clients and providers into each table of the star schema\n",
    "        format, for that it creates the id for each table.\n",
    "\n",
    "        After that loads the tables into the z3_results database.\n",
    "        \"\"\"\n",
    "        self._create_z3_indicators_dataframe_ids()\n",
    "        self._create_star_schema_tables()\n",
    "        self.z3_tables_dictionary: Dict[str, DataFrame] = {\n",
    "            'DATES': self.z3_dates_table,\n",
    "            'REPORTS': self.z3_reports_table,\n",
    "            'CLIENTS': self.z3_clients_table,\n",
    "            'PROVIDERS': self.z3_providers_table,\n",
    "            'INDICATORS': self.z3_indicators_table,\n",
    "            'EXECUTIONS': self.z3_executions_table\n",
    "        }\n",
    "        self._perform_load_queries()\n",
    "\n",
    "    def _create_z3_indicators_dataframe_ids(self):\n",
    "        \"\"\"Executes the method to create the ids for each table.\"\"\"\n",
    "        self._create_daily_id()\n",
    "        self._create_client_id()\n",
    "        self._create_report_id()\n",
    "        self._create_provider_id()\n",
    "        self._create_execution_id()\n",
    "\n",
    "    def _create_daily_id(self):\n",
    "        \"\"\"Takes the master data frame, gets the daily id based on its\n",
    "        value.\"\"\"\n",
    "        self.z3_indicators_master['daily_id'] = self.z3_indicators_master['daily'].copy(\n",
    "        )\n",
    "        change_column_datatype(self.z3_indicators_master, 'daily_id', 'str')\n",
    "        self.z3_indicators_master['daily_id'] = self.z3_indicators_master['daily_id'].apply(\n",
    "            lambda x: x.replace('/', ''))\n",
    "        change_column_datatype(self.z3_indicators_master, 'daily_id', 'int')\n",
    "\n",
    "    def _get_client_id(self, client: str) -> int:\n",
    "        \"\"\"Receives the client name and returns its id.\n",
    "\n",
    "        @param client: the client name.\n",
    "        @return client_id: the client id as an integer.\n",
    "        \"\"\"\n",
    "        return self.client_ids[client]\n",
    "\n",
    "    def _create_client_id(self):\n",
    "        \"\"\"Creates the client_id column, by executing the get_client_id into a\n",
    "        copy of the client names column.\"\"\"\n",
    "        self.z3_indicators_master['client_id'] = self.z3_indicators_master['client'].copy(\n",
    "        )\n",
    "        self.z3_indicators_master['client_id'] = self.z3_indicators_master['client_id'].apply(\n",
    "            self._get_client_id)\n",
    "        change_column_datatype(self.z3_indicators_master, 'client_id', 'int')\n",
    "\n",
    "    def _get_provider_id(self, provider: str) -> int:\n",
    "        \"\"\"Receives the provider name and returns its id.\n",
    "\n",
    "        @param provider: provider name.\n",
    "        @return: the id as an integer.\n",
    "        \"\"\"\n",
    "        return self.provider_ids[provider]\n",
    "\n",
    "    def _create_provider_id(self):\n",
    "        \"\"\"Creates the provider_id column.\"\"\"\n",
    "        self.z3_indicators_master['provider_id'] = self.z3_indicators_master['provider'].copy(\n",
    "        )\n",
    "        self.z3_indicators_master['provider_id'] = self.z3_indicators_master['provider_id'].apply(\n",
    "            self._get_provider_id)\n",
    "        change_column_datatype(self.z3_indicators_master, 'provider_id', 'int')\n",
    "\n",
    "    def _get_report_id(self, type_report: str) -> int:\n",
    "        \"\"\"Receives the report type and returns its id.\n",
    "\n",
    "        :param type_report: the report type.\n",
    "        :return report_id: the report id as an integer.\n",
    "        \"\"\"\n",
    "        return self.report_ids[type_report]\n",
    "\n",
    "    def _create_report_id(self):\n",
    "        \"\"\"Executes the _get_report_id method into the report_id column to get\n",
    "        the ids.\"\"\"\n",
    "        self.z3_indicators_master['report_id'] = self.z3_indicators_master['report_type'].copy(\n",
    "        )\n",
    "        self.z3_indicators_master['report_id'] = self.z3_indicators_master['report_id'].apply(\n",
    "            self._get_report_id)\n",
    "        change_column_datatype(self.z3_indicators_master, 'report_id', 'int')\n",
    "\n",
    "    def _create_execution_id(self):\n",
    "        \"\"\"Creates the execution_id column.\"\"\"\n",
    "        self.z3_indicators_master['execution_id'] = self.z3_indicators_master['execution_date'].copy(\n",
    "        )\n",
    "        change_column_datatype(self.z3_indicators_master,\n",
    "                               'execution_id', 'str')\n",
    "        self.z3_indicators_master['execution_id'] = self.z3_indicators_master['execution_id'].apply(\n",
    "            lambda x: x.replace('/', ''))\n",
    "        self.z3_indicators_master['execution_id'] = self.z3_indicators_master['execution_id'].apply(\n",
    "            lambda x: x.replace(':', ''))\n",
    "        self.z3_indicators_master['execution_id'] = self.z3_indicators_master['execution_id'].apply(\n",
    "            lambda x: x.replace('-', ''))\n",
    "\n",
    "        change_column_datatype(self.z3_indicators_master,\n",
    "                               'execution_id', 'int')\n",
    "\n",
    "    def _create_star_schema_tables(self):\n",
    "        \"\"\"Slices the z3_indicators_master dataframe that agglomerates the data\n",
    "        from all the clients and providers into each table of the star schema\n",
    "        format.\"\"\"\n",
    "        self._get_z3_dates_table()\n",
    "        self._get_z3_reports_table()\n",
    "        self._get_z3_clients_table()\n",
    "        self._get_z3_providers_table()\n",
    "        self._get_z3_indicators_table()\n",
    "        self._get_z3_executions_table()\n",
    "\n",
    "    def _get_z3_dates_table(self):\n",
    "        \"\"\"Copies the data from the master file into another dataframe that\n",
    "        will correspond to the dates table, it filters the column to the only\n",
    "        needed according to each table from the star schema defined.\"\"\"\n",
    "        self.z3_dates_table: DataFrame = self.z3_indicators_master.copy()\n",
    "        self.z3_dates_table: DataFrame = self.z3_dates_table[[\n",
    "            'daily_id', 'daily']]\n",
    "        self.z3_dates_table: DataFrame = create_date_yyyy_mm_dd(\n",
    "            self.z3_dates_table)\n",
    "        self.z3_dates_table = self.z3_dates_table.drop_duplicates(\n",
    "            subset='daily_id')\n",
    "\n",
    "    def _get_z3_reports_table(self):\n",
    "        \"\"\"Copies the data from the master file into another dataframe that\n",
    "        will correspond to the reports table, it filters the column to the only\n",
    "        needed according to each table from the star schema defined.\"\"\"\n",
    "        self.z3_reports_table: DataFrame = self.z3_indicators_master.copy()\n",
    "        self.z3_reports_table = self.z3_reports_table[[\n",
    "            'report_id', 'report_type']]\n",
    "        self.z3_reports_table = self.z3_reports_table.drop_duplicates(\n",
    "            subset='report_id')\n",
    "\n",
    "    def _get_z3_clients_table(self):\n",
    "        \"\"\"Copies the data from the master file into another dataframe that\n",
    "        will correspond to the clients table, it filters the column to the only\n",
    "        needed according to each table from the star schema defined.\"\"\"\n",
    "        self.z3_clients_table: DataFrame = self.z3_indicators_master.copy()\n",
    "        self.z3_clients_table = self.z3_clients_table[['client_id', 'client']]\n",
    "        self.z3_clients_table = self.z3_clients_table.drop_duplicates(\n",
    "            subset='client_id')\n",
    "\n",
    "    def _get_z3_providers_table(self):\n",
    "        \"\"\"Copies the data from the master file into another dataframe that\n",
    "        will correspond to the providers table, it filters the column to the\n",
    "        only needed according to each table from the star schema defined.\"\"\"\n",
    "        self.z3_providers_table: DataFrame = self.z3_indicators_master.copy()\n",
    "        self.z3_providers_table = self.z3_providers_table[[\n",
    "            'provider_id', 'provider']]\n",
    "        self.z3_providers_table = self.z3_providers_table.drop_duplicates(\n",
    "            subset='provider_id')\n",
    "\n",
    "    def _get_z3_indicators_table(self):\n",
    "        \"\"\"Copies the data from the master file into another dataframe that\n",
    "        will correspond to the indicators table, it filters the column to the\n",
    "        only needed according to each table from the star schema defined.\"\"\"\n",
    "        self.z3_indicators_table: DataFrame = self.z3_indicators_master.copy()\n",
    "        if 'scrapper_pos_qty' not in list(self.z3_indicators_table.columns):\n",
    "            self.z3_indicators_table['scrapper_pos_qty'] = 0\n",
    "            self.z3_indicators_table['scrapper_pos_sales'] = 0\n",
    "        elif 'scrapper_curr_on_hand_qty' not in list(self.z3_indicators_table.columns):\n",
    "            self.z3_indicators_table['scrapper_curr_on_hand_qty'] = 0\n",
    "\n",
    "        self.z3_indicators_table = self.z3_indicators_table[\n",
    "            ['client_id', 'report_id', 'provider_id', 'execution_id', 'daily_id', 'scrapper_pos_qty',\n",
    "             'scrapper_pos_sales', 'scrapper_curr_on_hand_qty', 'scrapper_rows']]\n",
    "\n",
    "    def _get_z3_executions_table(self):\n",
    "        \"\"\"Copies the data from the master file into another dataframe that\n",
    "        will correspond to the executions table, it filters the column to the\n",
    "        only needed according to each table from the star schema defined.\"\"\"\n",
    "        self.z3_executions_table: DataFrame = self.z3_indicators_master.copy()\n",
    "        if 'scrapper_pos_qty' not in list(self.z3_executions_table.columns):\n",
    "            self.z3_executions_table['scrapper_pos_qty'] = 0\n",
    "            self.z3_executions_table['scrapper_pos_sales'] = 0\n",
    "        elif 'scrapper_curr_on_hand_qty' not in list(self.z3_executions_table.columns):\n",
    "            self.z3_executions_table['scrapper_curr_on_hand_qty'] = 0\n",
    "\n",
    "        self.z3_executions_table = self.z3_executions_table[[\n",
    "            'execution_id', 'execution_date']]\n",
    "        self.z3_executions_table: DataFrame = create_date_yyyy_mm_dd_hh_mins(\n",
    "            self.z3_executions_table, 'execution_date')\n",
    "\n",
    "    def _perform_load_queries(self) -> DataFrame:\n",
    "        \"\"\"Creates the tables and inserts the data into the z3_results\n",
    "        database.\"\"\"\n",
    "        db_name: str = \"z3_results\"\n",
    "        connection: str = f\"host={self.z3_results_host_db} dbname={db_name} user={self.z3_results_user_db} password={self.z3_results_password_db}\"\n",
    "        conn = psycopg2.connect(connection)\n",
    "        try:\n",
    "            conn.set_session(autocommit=True, readonly=False)\n",
    "            cur = conn.cursor()\n",
    "\n",
    "            self._create_tables(cur)\n",
    "            self._insert_tables(cur)\n",
    "\n",
    "        except psycopg2.Error as e:\n",
    "            logging.info(e)\n",
    "\n",
    "        finally:\n",
    "            conn.close()\n",
    "\n",
    "    @staticmethod\n",
    "    def _create_tables(cur):\n",
    "        \"\"\"Runs the creating tables extract_and_quality.\n",
    "\n",
    "        @cur: database cursor\n",
    "        @conn: database connection\n",
    "        \"\"\"\n",
    "        for query in create_table_queries:\n",
    "            cur.execute(query)\n",
    "\n",
    "    def _insert_tables(self, cur):\n",
    "        \"\"\"Distributes the information into each table from the star schema.\n",
    "\n",
    "        @cur: database cursor\n",
    "        @conn: database connection\n",
    "        \"\"\"\n",
    "        for key in list(insert_table_queries_dict.keys()):\n",
    "            query: str = insert_table_queries_dict[key]\n",
    "            dataframe: DataFrame = self.z3_tables_dictionary[key]\n",
    "            for _, row in dataframe.iterrows():\n",
    "                cur.execute(query, list(row))\n",
    "\n",
    "    def data_quality_checks(self):\n",
    "        \"\"\"Tests if the data processed corresponds to the data loaded into the\n",
    "        database.\"\"\"\n",
    "        database_result: DataFrame = self._perform_data_quality_query()\n",
    "        database_pos_qty: float = database_result['database_pos_qty'].sum()\n",
    "        database_pos_sales: float = database_result['database_pos_sales'].sum()\n",
    "        database_curr_on_hand_qty: float = database_result['database_curr_on_hand_qty'].sum(\n",
    "        )\n",
    "        database_rows: float = database_result['database_rows'].sum()\n",
    "        database_dailys: List[str] = database_result['daily'].unique()\n",
    "\n",
    "        scrapper_pos_qty: float = self.z3_indicators_table['scrapper_pos_qty'].sum(\n",
    "        )\n",
    "        scrapper_pos_sales: float = self.z3_indicators_table['scrapper_pos_sales'].sum(\n",
    "        )\n",
    "        scrapper_rows: float = self.z3_indicators_master['scrapper_rows'].sum()\n",
    "        scrapper_curr_on_hand_qty: float = self.z3_indicators_table['scrapper_curr_on_hand_qty'].sum(\n",
    "        )\n",
    "        scrapper_dailys: List[str] = self.z3_dates_table['daily'].unique()\n",
    "\n",
    "        assert database_pos_qty == pytest.approx(scrapper_pos_qty, 0.2)\n",
    "        assert database_pos_sales == pytest.approx(scrapper_pos_sales, 0.2)\n",
    "        assert database_curr_on_hand_qty == pytest.approx(\n",
    "            scrapper_curr_on_hand_qty, 0.2)\n",
    "        assert database_rows == pytest.approx(scrapper_rows, 0.2)\n",
    "        assert all(record in scrapper_dailys for record in database_dailys)\n",
    "\n",
    "    def _perform_data_quality_query(self) -> DataFrame:\n",
    "        \"\"\"Queries the z3_results database, and takes the result into a\n",
    "        dataframe.\"\"\"\n",
    "        db_name: str = \"z3_results\"\n",
    "        connection: str = f\"host={self.z3_results_host_db} dbname={db_name} user={self.z3_results_user_db} \" \\\n",
    "                          f\"password={self.z3_results_password_db}\"\n",
    "        df_quality: DataFrame = pd.DataFrame()\n",
    "        conn = psycopg2.connect(connection)\n",
    "        try:\n",
    "            conn.set_session(autocommit=True, readonly=True)\n",
    "            cur = conn.cursor()\n",
    "            cur.execute(quality_checks)\n",
    "\n",
    "            df_quality: DataFrame = DataFrame(\n",
    "                cur.fetchall(),\n",
    "                columns=columns_quality_checks,\n",
    "            )\n",
    "        except psycopg2.Error as e:\n",
    "            logging.info(e)\n",
    "\n",
    "        finally:\n",
    "            conn.close()\n",
    "\n",
    "        return df_quality\n",
    "\n",
    "    @staticmethod\n",
    "    def drop_tables():\n",
    "        \"\"\"Drops all the tables in the z3_results database.\"\"\"\n",
    "        load_dotenv(find_dotenv())\n",
    "        z3_results_password_db: str = os.getenv(\"RESULTS_PASSWORD\")\n",
    "        z3_results_user_db: str = os.getenv(\"RESULTS_USER_DB\")\n",
    "        z3_results_host_db: str = os.getenv(\"RESULTS_HOST_DB\")\n",
    "        db_name: str = \"z3_results\"\n",
    "        connection: str = f\"host={z3_results_host_db} dbname={db_name} \" \\\n",
    "                          f\"user={z3_results_user_db} password={z3_results_password_db}\"\n",
    "        conn = psycopg2.connect(connection)\n",
    "        try:\n",
    "            conn.set_session(autocommit=True, readonly=False)\n",
    "            cur = conn.cursor()\n",
    "            for query in drop_table_queries:\n",
    "                cur.execute(query)\n",
    "        except psycopg2.Error as e:\n",
    "            logging.info(e)\n",
    "\n",
    "        finally:\n",
    "            conn.close()\n",
    "\n",
    "    def main(self):\n",
    "        \"\"\"Directs the execution order of each method.\"\"\"\n",
    "        self.extract_and_transform_each_provider_and_client()\n",
    "        self.load()\n",
    "        self.data_quality_checks()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 5: Complete project write up\n",
    "#### Whats' the goal?\n",
    "The goal is to make sure data makes sense once it is into the scrappers database, since that data is going into the clients BI side.\n",
    "\n",
    "### How would Spark or Airflow be incorporated?\n",
    "The project is kind of thinked to be taken into an airflow dag, each of the steps is a clearly defined action that can be re-coded into python operators, spark will be implemented in case the data amount grows exponentially, at this point after summarizing the results the cost of processing is low, so that's the only way that implementing spark would be worth doing.\n",
    "\n",
    "\n",
    "#### Choice of technologies\n",
    "* Database: Postgresql as the open source, user friendly technology and big data capabilites once the data amount grows.\n",
    "* Data wrangling: Pandas, one of the best libraries to manipulate and analyze dataframes, I also have plenty of experience with pandas.\n",
    "* User Interface: Jupyter lab: As a easy to use python interface that let's you run the code with a simple click.\n",
    "\n",
    "#### Data updates\n",
    "The data must be updating everyday at 9:30 am, in order to spot useless data and have time to regenerate the reports before the client sees it on the Bussiness Intelligence report.\n",
    "\n",
    "#### Scenarios\n",
    "* Data was increased to 100x: In this case the option can be to implement Spark into the project to run the etl on parallel with EMR instances. Other solution would be to add more processing units to each database in order to accomplish the extract query, probably the other step would be to separate each client into its z3 database, since I am putting all the data togheter into one database. \n",
    "* 7am update: Get the project into an airflow DAG, so nobody will have to execute the jupyter lab manually.\n",
    "* If the database needed to be accessed by 100+ people: Implement a distributed database in order to have high availability.\n",
    "Another solution is to increase the database hardware, another way to solve this depending on the needs is to implement views to 'pre-load' the most complex queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
